1- We looked for models hosted elsewhere to not have to possess large memory to store the model, as well as gpus. For 
hg that is why we opted for the inference api instead of downloading the models

You can access the sentiment classifier via both a post request or an html

curl to use in cmd:
curl -X POST https://sentiment-usecase.onrender.com/predict -H "Content-Type: application/json" -d '{ "review": "my wife is amazing" }'

script to log models can be used for any model (script to generate predictions outputs them in a unified format). hence we run it with argparse

recycle code for different runs